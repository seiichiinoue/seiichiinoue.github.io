<!DOCTYPE html>
<html lang="ja">
    <head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<title>
				[論文読み] RoBERTa &middot; いのうの作業ログ
		</title>

		
  		<link rel="stylesheet" href="https://seiichiinoue.github.io/css/style.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
		
		<link rel="icon" type="image/png" sizes="32x32" href="https://seiichiinoue.github.io/images/favicon.png">
        
		<link rel="apple-touch-icon" sizes="180x180" href="https://seiichiinoue.github.io/images/favicon.png">
        
		
		<link href="" rel="alternate" type="application/rss+xml" title="いのうの作業ログ" />
	</head>

    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="https://seiichiinoue.github.io/">
					<h2 class="nav-title">いのうの作業ログ</h2>
				</a>
				<ul>
    <li><a href="https://seiichiinoue.github.io/about">About</a></li>
    <li><a href="https://seiichiinoue.github.io/">Posts</a></li>
</ul>
			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
        <br>
        <time datetime="2019-07-31 03:13:29 &#43;0900 JST">July 31, 2019</time>
</div>

		<h1 class="post-title">[論文読み] RoBERTa</h1>
<div class="post-line"></div>

		

		

<p>先日，Facebook AIがGLUEやSQuADでGoogleのBERTを超えたと話題になっていたモデルの<a href="https://arxiv.org/abs/1907.11692">論文</a>を公開したらしいので概要をまとめました．</p>

<h1 id="概要">概要</h1>

<ul>
<li>GLUE, SQuAD, RACEで評価．</li>
</ul>

<p>以下の改良でsota達成らしい．</p>

<ul>
<li>コーパスサイズを大きくした</li>
<li>Next Sentence Predictionをやめた</li>
<li>pretrainingを長くした</li>
<li>pretrainingのマスクを毎回かえた</li>
<li>batchsizeを大きくした</li>
</ul>

<h1 id="実験詳細">実験詳細</h1>

<h2 id="static-vs-dynamic-masking">Static vs Dynamic Masking</h2>

<ul>
<li>オリジナルのBERTモデルでは前処理段階でmaskingを行い，以後変更なしで学習を進める．</li>
<li>RoBERTaでは同じmaskingを用いて学習することを避けるため，40回の学習で10通りのmaskigを適用したデータセットを用いる．</li>
<li>実験の結果fine tuningを用いた様々な後続タスクでstaticを超えるスコアを出した．</li>
</ul>

<h2 id="model-input-format-and-next-sentence-prediction">Model Input Format and Next Sentence Prediction</h2>

<ul>
<li>オリジナルのBERTでは50%の確率で同じdocumentのsegmentを（残りの50%でそうではないsegmentを）繋げて2文を1 sequenceとして入力としていた．</li>
<li>また，それを用いて行われる隣接文予測タスクによる誤差はオリジナルBERTモデルにおいて重要とされていた（文脈を考慮した文章埋め込みを取得するために必要なタスクであるという主張だった記憶）</li>
<li>実験は以下の通り

<ul>
<li>まず，Segment-Pair+NSP / Sentence-Pair+NSPの比較</li>
<li>NSP / non-NSPの比較</li>
<li>Doc-Sentence / Full-Sentenceの比較</li>
</ul></li>
<li>Segment中にSentenceが複数個あっても良いSegment-Pairと，必ず1つのSentence同士を結合して使うSentence-PairでそれぞれNext Sentence Predictionを行った結果，Single-Sentenceを使うことは後続のタスクのパフォーマンスに悪影響を与えることがわかった．</li>
<li>NSPを除いたほうが後続タスクの性能があがることがわかった</li>
<li>コーパスを作成するときに，全てのdocumentを跨ぐより一つのdocumentからという制約をつけたほうが性能がいいことがわかった</li>
</ul>

<h2 id="training-large-batches">Training Large Batches</h2>

<ul>
<li>適切に学習率が増加した際は，バッチサイズを大きくしてもうまく行くことが実験的にわかった．</li>
<li>事前学習の精度に加えて後続のタスクのスコアも上昇することがわかった</li>
</ul>


		
	</div>

	<div class="pagination">
		<a href="https://seiichiinoue.github.io/post/tobit/" class="left arrow">&#8592;</a>
		<a href="https://seiichiinoue.github.io/post/abc134c/" class="right arrow">&#8594;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2019-08-01 18:12:48.292225 &#43;0900 JST m=&#43;0.065323384">2019</time> . Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
            <script type="text/x-mathjax-config">
                MathJax.Hub.Config({
                    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
                });
            </script>
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		</footer>

    </body>
</html>
