<!DOCTYPE html>
<html lang="ja">
    <head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<title>
				A Bayesian Model of Diachronic Meaning Changeの実装 &middot; 冴えない院生の育てかた
		</title>

		
  		<link rel="stylesheet" href="https://seiichiinoue.github.io/css/style.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
		
		<link rel="icon" type="image/png" sizes="32x32" href="https://seiichiinoue.github.io/img/favicon.png">
        
		<link rel="apple-touch-icon" sizes="180x180" href="https://seiichiinoue.github.io/img/favicon.png">
        
		
		<link href="" rel="alternate" type="application/rss+xml" title="冴えない院生の育てかた" />
	</head>

    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="https://seiichiinoue.github.io/">
					<h2 class="nav-title">冴えない院生の育てかた</h2>
				</a>
				<ul>
    <li><a href="https://seiichiinoue.github.io/about">About</a></li>
    <li><a href="https://seiichiinoue.github.io/">Posts</a></li>
</ul>

			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
        <br>
        <time datetime="2021-04-26 20:11:23 &#43;0900 JST">April 26, 2021</time>
</div>

		<h1 class="post-title">A Bayesian Model of Diachronic Meaning Changeの実装</h1>
<div class="post-line"></div>

		

		

<p>今回実装したのは，通時的な意味変化を捉えるトピックモデルです．2016年のTACL論文になります．以下論文です．</p>

<p><a href="https://www.aclweb.org/anthology/Q16-1003.pdf">https://www.aclweb.org/anthology/Q16-1003.pdf</a></p>

<p>実装後に発見したのですが，一応著者が公開している実装もあるらしいです（しかしGoで書かれていて，超絶読みづらいです）．</p>

<p>僕の実装は以下になります:</p>

<p><a href="https://github.com/seiichiinoue/scan">https://github.com/seiichiinoue/scan</a></p>

<h2 id="dynamic-bayesian-model-of-sense-change-scan">Dynamic Bayesian Model of Sense Change (SCAN)</h2>

<p>前置きとして，このモデルは単語の意味変化を捉えるためのモデルになっています．</p>

<p>データが少し特殊で，word-specific documentsを用いて学習します．意味変化を検出したいtarget wordの周辺単語を任意の文脈窓幅$I$について</p>

<div style="overflow-x: auto;">
$$d_i = (t_{-I}, t_{-I+1}, \ldots, t_{-1}, t, t_{1}, \ldots, t_{I-1}, t_{I})$$
</div>

<p>というような文書を仮定します．</p>

<p>この文書に対して，year label (正確な年は必要なく，どの文書集合がどの年代のものかがわかればよい) が付与されていて，その文書のyear labelを使って時期ごとにパラメータを設定し，それぞれの時期間に相関を持たせながら学習するようなモデルになっています．</p>

<p>本モデルでは，時点$t$のtemporal meaning representationとして，K次元のトピック分布$\phi^t$とV次元の単語分布$\psi^{t, k}$を仮定します．また，時点間でのトピック分布の変化を制御するための精度パラメータである$\kappa^{\phi}$を導入します．</p>

<p>上述の精度パラメータを使って，どのように時点間の相関をもたせるかですが，それは多項分布$\phi$, $\psi$の事前分布にlogistic normalを置くことで実現します．logistic normalに従う多項分布パラメータは，$n$次元のランダムベクトル$\mathbf{x}$が$n$次元の平均ベクトル$\mathbf{\mu}$，$n \times n$次元の分散共分散行列$\Sigma$によるガウス分布から生成され:</p>

<div style="overflow-x: auto;">
$$\mathbf{x} \sim \mathcal{N} (\mathbf{x} | \mathbf{\mu}, \Sigma)$$
</div>

<p>それを次のようにロジスティック変換することにより単体上に射影する（0 ~ 1の確率に変換する）ことで生成されます．</p>

<div style="overflow-x: auto;">
$$\phi_n = \frac{\exp(x_n)}{\sum_{n^{\prime}} \exp(x_n^{\prime})}$$
</div>

<p>このように事前分布にガウス分布を置くことで，分散を通してパラメータの変化の度合いをコントロールできます．</p>

<p>以下にSCANのグラフィカルモデルと生成モデルを示します．</p>

<p><img src="https://img.esa.io/uploads/production/attachments/14410/2021/04/27/91632/d86959e0-8887-44fd-b0e5-5cba535a3625.png"></p>

<p>まず，トピック精度パラメータ$\kappa^{\phi}$を共役事前分布であるGamma分布から生成します．</p>

<p>次に，それぞれの時点$t$において，logistic normal事前分布からトピック分布$\phi^{t}$を生成し，それぞれのトピック$k$について，同様にlogistic normal事前分布から単語分布$\psi^{t, k}$を生成します．</p>

<p>そして，各文書に対して，トピック$z^d$を多項分布$Mult(\phi^t)$から生成し，文脈窓幅$I$回文脈単語を多項分布$Mult(\psi^{t, z_d})$から独立に生成する流れになります．</p>

<p>ここで，トピック分布 (論文中ではsense distributionと呼ばれている) と単語分布について，$t - 1$時点と$t + 1$時点のパラメータの平均を事前分布の平均としていますが，これは，intrinsic Gaussian Markov Random Field (iGMRF) であり，時期間のパラメータに相関を持たせ，変化を捉えることを可能としています．</p>

<h2 id="推論">推論</h2>

<p>SCANの推定パラメータは，潜在変数である文書のトピック$z$，トピック分布$\phi$，単語分布$\psi$，トピック分布のlogistic normal事前分布のパラメータ$\kappa$です．</p>

<p>推定にはblocked Gibbs Samplerを用います．一般に，トピックモデルは多項分布-Dirichlet分布を用いて離散変数のモデル化を行うことが多いのですが，SCANは多項分布の事前分布に共役ではないガウス分布を仮定しているので，同様に推定することはできません．
そのため，Mimnoらから提案された補助変数を用いたlogistic normal priorに従うパラメータ推定法を用います．</p>

<p>大まかな流れとしては，文書のトピックを他のパラメータを固定した状態でサンプルし，次にトピックと単語の多項分布のパラメータを同様に他のパラメータを固定してサンプルし，最後に精度パラメータをサンプルする，という感じです．</p>

<h3 id="トピックのサンプリング">トピックのサンプリング</h3>

<p>文書のトピックは，他のパラメータを全て固定した上で以下の条件付き確率に従ってサンプルされます．</p>

<div style="overflow-x: auto;">
\begin{eqnarray}
p(z^d | \mathbf{w}, t, \phi, \psi) &\propto& p(z^d | t) p(\mathbf{w} | t, z^d)\\\\
&=& \phi^{t}_{z^d} \prod_{w \in \mathbf{w}} \psi^{t, z^d}_w 
\end{eqnarray}
</div>

<p>各文書に対して，上式を用いて各トピックの確率を計算することでトピックの確率分布（実際には正規化されていない）が得られます．
著者実装では，正規化されてないパラメータを用いたランダムサンプラー（？）的な何かを使ってサンプリングしていましたが，私は普通に多項分布を用いてサンプルしました．</p>

<p>多項分布を用いてサンプルする際は，一般に正規化された確率を引数に渡してあげなければならないのですが，上式から分かる通り，$\prod \psi^{z^d}_w &lt;&lt; 0$であるため，underflowしないようにlogsumexp<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>等を使わなければならないことに注意です．</p>

<h3 id="logistic-normalパラメータのサンプリング">logistic normalパラメータのサンプリング</h3>

<!--
トピックが与えられたとき，事後確率は

<div style="overflow-x: auto;">
$$p( \phi_ | \mathbf{z}, \mathbf{\mu}, \kappa, t) \propto \prod_{d=1}^{D} \prod_{k=1}^K \frac{\exp(\phi^t_{k})}{\sum_{k=1}^{K} \exp(\phi^t_k)} \mathcal{N} (\mathbf{\mu}, \kappa)$$
</div>

となります．結果的にトピック分布$\phi$を推定することは，文書のindexを入力として，トピック$z$をラベルとした時の，ガウス事前分布を用いたロジスティック回帰のパラメータを学習することと等価です．

一般にロジスティック回帰は数値最適化で推定されますが，今回はMCMC法を用いる手法を用います．以下，簡単のためトピック分布を$\phi$と略記します．
-->

<p>上述の通り本モデルでは，多項分布の事前分布に共役でないlogistic normalを考えているので，LDAなどで用いられるサンプリング手法は用いることができません．
logistic normalパラメータを推定する方法として，Polya-Gamma分布を用いたサンプリング<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup>がありますが，本実装では，補助変数を用いた推定方法を用いました．</p>

<p>次のような生成過程を考えてみます．</p>

<ol>
<li>$\beta$をガウス分布から生成</li>
<li>$\beta$をロジスティック変換する: $\phi = \exp(\beta) / \sum \exp(\beta)$</li>
<li>それぞれの文書に対して，トピックを生成: $z_n \sim \mathrm{Mult} (\phi)$</li>
</ol>

<p>このとき，$\phi$はロジスティック分布のCDFとも解釈することができます:</p>

<div style="overflow-x: auto;">
$$\phi = \frac{\exp(\beta)}{\sum \exp(\beta)} = \int_{-\inf}^{\beta} \frac{\exp(x)}{(\sum \exp(x))^2} \mathrm{d}x$$
</div>

<p>よって，トピック$z$は下図のように多項分布からサンプルされることになります．</p>

<p><img src="https://img.esa.io/uploads/production/attachments/14410/2021/04/16/91632/d2b8f88f-998c-42d4-bd52-3996a1a1dca7.png"></p>

<ol>
<li>CDF上の$\beta$の点を通るvertical lineを引く．</li>
<li>補助変数をそれぞれの文書に対し，一様分布からサンプルする: $u_n \sim \mathcal{U} (0,1)$</li>
<li>$u_n$を$\beta$上にプロットする．</li>
<li>もし$u_n$がCDF曲線よりも下に位置するなら（$\phi = \exp(\beta) / \sum \exp(\beta)$よりも小さければ），z = kとする．上に位置するならz $\neq$ kとする．</li>
</ol>

<p>同様に，$\beta$の初期値が決まっていれば，$z$から$\beta$を推定することもできます．k番目のトピック分布のパラメータを推定すること考えます．</p>

<p>まずは補助変数を次のように生成し，</p>

<ol>
<li>CDF上，現在の$\beta$の点を通るvertical lineを引く．</li>
<li>それぞれの文書に対して

<ol>
<li>z = kの場合，$u_n$を次の一様分布から生成: $u_n \sim U(0, \phi)$</li>
<li>z $\neq$ kの場合，$u_n$を次の一様分布から生成: $u_n \sim U(\phi, 1)$</li>
</ol></li>
</ol>

<p>全ての文書に対して補助変数を得たら，$\beta$の推定範囲は次のようになります．</p>

<div style="overflow-x: auto;">
$$ max_{z = k} log \left( \frac{C u_n}{1 - u_n} \right) < \beta < min_{z \neq k} log \left( \frac{C u_n}{1 - u_n} \right) $$
</div>

<p>ただし，Cは定数で</p>

<div style="overflow-x: auto;">
$$ C = \sum_{k} \exp(\beta_k^{\prime}) (1 - \delta(k^{\prime} - k))$$
</div>

<p>となります．あとは，事前分布はガウス分布なので，この範囲で切断された，平均$\frac{1}{2} (\phi^{t-1} + \phi^{t+1})$，分散$\kappa_{\phi}$の切断正規分布からサンプルすればよいです．</p>

<p>Tipsとして，n個の一様分布からサンプリングされた確率変数はベータ分布に従う性質を使うと，補助変数はn個全て生成する必要なく，計算量を削減できます．</p>

<p>単語分布についても，トピック分布と同様に補助変数法を用いてサンプルを行います．
トピック分布においては，文書の数だけ補助変数を生成しましたが，これを文書*各文書毎に現れる単語数分だけ生成し，単語分布を更新していきます．</p>

<h2 id="結果">結果</h2>

<p>COHA (Corpus of Historical American English) を使って実験しました．1810-2009までの文書があり，冒頭で説明した通り，解析対象の単語の周辺単語を抜き取って文書を作成し，対象単語ごとにモデルを作成しました．
以下では&rdquo;transport&rdquo;を対象に学習を行なった結果を示します．</p>

<!--
実際に各時点におけるトピック分布とトピック毎の確率の高い単語の可視化なんかも載せたいのですが，研究室にあるコーパスを使用しての実験となるため本サイトでの公開は控えさせてもらいます．ひとまずperplexityの推移のみ掲載します．
-->

<p>以下perplexiyの推移です．</p>

<p><img src="https://img.esa.io/uploads/production/attachments/14410/2021/04/26/91632/3615e441-5326-4b40-bb80-951fb247f39d.png" width=70%></p>

<p>トピック確率と単語分布を用いて，各時点における支配的なトピックと推移，また確率上位の単語を可視化しました．</p>

<p><img src="https://img.esa.io/uploads/production/attachments/14410/2021/04/27/91632/c4a2b734-ecb7-4133-a2cc-57ca4bd056d5.png"></p>

<p>凡例には1810年におけるトピック毎の確率上位単語を10個載せました．</p>

<p>茶色で示されるトピックは，joyやheartなどが確率上位となっており，昔はそういった単語と共起する確率が高かったことがわかります（自分は，単語の意味変化に詳しくないのですが，昔はa transports of joy的な使われ方をしていたみたいです<sup class="footnote-ref" id="fnref:3"><a href="#fn:3">3</a></sup>）．また，茶色で示されるトピックは昔は支配的であったのに対し，現在になるにつれて，支配率が低くなっていることもわかります．</p>

<p>現在は，青色で示されるトピック，つまり流通や移動手段に関する単語として使われることが多いこともわかりました．</p>

<h2 id="まとめ">まとめ</h2>

<p>意味変化を捉える研究は大量にあって（自分は全て網羅できているわけでは到底ありません），研究室の先輩は単語分散表現を用いて意味変化の検出を行うといったことをしてたりするんですが，トピックモデルを使うと解釈がしやすく，分析をする際は有用だなと思いました．</p>

<p>今回実装したモデルはword-specific documentsを使った意味変化のトピックモデルで，target wordをあらかじめ決めることでその周辺単語集合をモデル化する手法でした．実際の用途としては「統計的に意味変化があった単語を発見したい」ということが多いので，target wordをあらかじめ決めることなく同様のモデリングができたら面白そうだな，と思ってます．</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">python等だとライブラリがうまくやってくれるはずなので特に意識しなくていいです．
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2">LindermanらのDependent Multinomial Models Made Easy: Stick Breaking with the Polya-Gamma Augmentationが詳しいです．
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
<li id="fn:3">「喜びに我を忘れて」という意味らしい
 <a class="footnote-return" href="#fnref:3"><sup>[return]</sup></a></li>
</ol>
</div>


        <h2 id="related">See Also</h2>

		
	</div>
     
	<div class="pagination">
		<a href="https://seiichiinoue.github.io/post/mlrbf/" class="left arrow">&#8592;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2021-04-27 20:50:06.262476 &#43;0900 JST m=&#43;0.149221646">2021</time> Seiichi Inoue. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
            <script type="text/javascript" src="https://seiichiinoue.github.io/js/related.js"></script>
            <script type="text/x-mathjax-config">
                MathJax.Hub.Config({
                    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
                });
            </script>
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		</footer>

    </body>
</html>
